{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "abbreviation_extraction_revamped.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPU2DCJhtxP4k9AHDOg2ztI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/petermr/semanticClimate/blob/main/abbreviation/Codes/abbreviation_extraction_revamped.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYvAiLwLk-e8",
        "outputId": "1df5b609-3843-415f-fb50-b457ca062499"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting abbreviations\n",
            "  Downloading abbreviations-0.2.5-py3-none-any.whl (5.7 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from abbreviations) (2022.6.2)\n",
            "Installing collected packages: abbreviations\n",
            "Successfully installed abbreviations-0.2.5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scispacy==0.3.0\n",
            "  Downloading scispacy-0.3.0-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.3 in /usr/local/lib/python3.7/dist-packages (from scispacy==0.3.0) (1.0.2)\n",
            "Collecting spacy<3.0.0,>=2.3.0\n",
            "  Downloading spacy-2.3.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 47.5 MB/s \n",
            "\u001b[?25hCollecting nmslib>=1.7.3.6\n",
            "  Downloading nmslib-2.1.1-cp37-cp37m-manylinux2010_x86_64.whl (13.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.5 MB 36.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0conllu,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scispacy==0.3.0) (2.23.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from scispacy==0.3.0) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from scispacy==0.3.0) (1.21.6)\n",
            "Collecting pysbd\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[K     |████████████████████████████████| 71 kB 9.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from nmslib>=1.7.3.6->scispacy==0.3.0) (5.4.8)\n",
            "Collecting pybind11<2.6.2\n",
            "  Downloading pybind11-2.6.1-py2.py3-none-any.whl (188 kB)\n",
            "\u001b[K     |████████████████████████████████| 188 kB 63.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0conllu,>=2.0.0->scispacy==0.3.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0conllu,>=2.0.0->scispacy==0.3.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0conllu,>=2.0.0->scispacy==0.3.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0conllu,>=2.0.0->scispacy==0.3.0) (2022.6.15)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.3->scispacy==0.3.0) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.3->scispacy==0.3.0) (3.1.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.0->scispacy==0.3.0) (4.64.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.0->scispacy==0.3.0) (2.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.0->scispacy==0.3.0) (3.0.6)\n",
            "Collecting thinc<7.5.0,>=7.4.1\n",
            "  Downloading thinc-7.4.5-cp37-cp37m-manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 59.9 MB/s \n",
            "\u001b[?25hCollecting catalogue<1.1.0,>=0.0.7\n",
            "  Downloading catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)\n",
            "Collecting plac<1.2.0,>=0.9.6\n",
            "  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.0->scispacy==0.3.0) (57.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.0->scispacy==0.3.0) (0.9.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.0->scispacy==0.3.0) (1.0.7)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.0->scispacy==0.3.0) (0.7.7)\n",
            "Collecting srsly<1.1.0,>=1.0.2\n",
            "  Downloading srsly-1.0.5-cp37-cp37m-manylinux2014_x86_64.whl (184 kB)\n",
            "\u001b[K     |████████████████████████████████| 184 kB 68.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.3.0->scispacy==0.3.0) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.3.0->scispacy==0.3.0) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.3.0->scispacy==0.3.0) (4.1.1)\n",
            "Installing collected packages: srsly, plac, catalogue, thinc, pybind11, spacy, pysbd, nmslib, scispacy\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 2.4.3\n",
            "    Uninstalling srsly-2.4.3:\n",
            "      Successfully uninstalled srsly-2.4.3\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 2.0.7\n",
            "    Uninstalling catalogue-2.0.7:\n",
            "      Successfully uninstalled catalogue-2.0.7\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.0.17\n",
            "    Uninstalling thinc-8.0.17:\n",
            "      Successfully uninstalled thinc-8.0.17\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.3.1\n",
            "    Uninstalling spacy-3.3.1:\n",
            "      Successfully uninstalled spacy-3.3.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.3.0 requires spacy<3.4.0,>=3.3.0.dev0, but you have spacy 2.3.7 which is incompatible.\u001b[0m\n",
            "Successfully installed catalogue-1.0.0 nmslib-2.1.1 plac-1.1.3 pybind11-2.6.1 pysbd-0.3.4 scispacy-0.3.0 spacy-2.3.7 srsly-1.0.5 thinc-7.4.5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en_core_web_sm==2.3.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 11.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.3.1) (2.3.7)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (57.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.64.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.9.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.7.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.21.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.7)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.11.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
            "Building wheels for collected packages: en-core-web-sm\n",
            "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.3.1-py3-none-any.whl size=12047105 sha256=12b21b5cefc2ae8aa68e83de7d599f5c97e6d0a164f9b48b71bf0a3f756e8b57\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/0d/f0/7ecae8427c515065d75410989e15e5785dd3975fe06e795cd9\n",
            "Successfully built en-core-web-sm\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 3.3.0\n",
            "    Uninstalling en-core-web-sm-3.3.0:\n",
            "      Successfully uninstalled en-core-web-sm-3.3.0\n",
            "Successfully installed en-core-web-sm-2.3.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!pip install abbreviations\n",
        "!pip install scispacy==0.3.0\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone  https://github.com/petermr/semanticClimate.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaN2FeZkqK3T",
        "outputId": "d2d1a7f1-b62e-40ee-fcd7-0153e79fbcb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'semanticClimate'...\n",
            "remote: Enumerating objects: 1261, done.\u001b[K\n",
            "remote: Counting objects: 100% (313/313), done.\u001b[K\n",
            "remote: Compressing objects: 100% (207/207), done.\u001b[K\n",
            "remote: Total 1261 (delta 118), reused 222 (delta 71), pack-reused 948\u001b[K\n",
            "Receiving objects: 100% (1261/1261), 138.81 MiB | 36.54 MiB/s, done.\n",
            "Resolving deltas: 100% (199/199), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import scispacy\n",
        "from bs4 import BeautifulSoup\n",
        "from abbreviations import schwartz_hearst\n",
        "from scispacy.abbreviation import AbbreviationDetector\n",
        "from IPython.display import HTML\n",
        "import pandas as pd\n",
        "import requests\n",
        "import os\n",
        "dict_abbreviation = {}\n",
        "\n",
        "class abbreviation_extraction():\n",
        "  def __init__(self, html_path, saving_path, model):\n",
        "    self.html_path = html_path\n",
        "    self.saving_path = saving_path\n",
        "    self.dict_abbreviation = {}\n",
        "    self.dict_abbreviation_swartz = {}\n",
        "    self.text = ''\n",
        "\n",
        "  def make_clickable(val):\n",
        "          #print(type(val))\n",
        "          l = [f'<a target=\"_blank\" href=\"{val_}\">{val_}</a>' for val_ in val]\n",
        "          return l\n",
        "  def wikidata_lookup(self, row):\n",
        "          query = row['long_form']\n",
        "          #print('query',query)\n",
        "          params\t= {\n",
        "                  \"action\"\t\t: \"wbsearchentities\",\n",
        "                  \"search\"\t\t: query,\n",
        "                  \"language\"\t: \"en\",\n",
        "                  \"format\"\t\t: \"json\"\n",
        "                }\n",
        "          data\t= requests.get(\"https://www.wikidata.org/w/api.php\",params=params)\n",
        "          result = data.json()\n",
        "          hit_list = []\n",
        "          for hit in result['search']:\n",
        "            try:\n",
        "              if \"scientific article\" not in hit[\"description\"]:\n",
        "                  hit_list.append(hit[\"url\"])\n",
        "            except:\n",
        "                  hit_list.append(hit[\"url\"])\n",
        "          return hit_list\n",
        "  \n",
        "  def text_extraction(self):\n",
        "    with open(self.html_path, 'r') as f:\n",
        "      html = f.read()\n",
        "      soup = BeautifulSoup(html, features=\"html.parser\")\n",
        "\n",
        "      # kill all script and style elements\n",
        "      for script in soup([\"script\", \"style\"]):\n",
        "          script.extract()    # rip it out\n",
        "\n",
        "      # get text\n",
        "      text = soup.get_text()\n",
        "\n",
        "      # break into lines and remove leading and trailing space on each\n",
        "      lines = (line.strip() for line in text.splitlines())\n",
        "      # break multi-headlines into a line each\n",
        "      chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
        "      # drop blank lines\n",
        "      #text_write = '\\n'.join(chunk for chunk in chunks if chunk)\n",
        "      self.text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
        "      #print(text)\n",
        "    return self.text\n",
        "\n",
        "  def scispacy_extraction(self, doc):\n",
        "    for abrv in doc._.abbreviations:\n",
        "        new_dict  ={}\n",
        "        abrv_ = str(abrv)\n",
        "        long_f = str(abrv._.long_form)\n",
        "        if '(' in  long_f or ')' in long_f or abrv_ == long_f or abrv_ == long_f +'s':\n",
        "            continue\n",
        "        else:  \n",
        "            if abrv_ not in self.dict_abbreviation:\n",
        "              new_dict['long_form']= abrv._.long_form\n",
        "              new_dict['count'] = int(1)\n",
        "              self.dict_abbreviation[str(abrv)] = new_dict  \n",
        "            else:  \n",
        "              self.dict_abbreviation[str(abrv)]['count'] = int(self.dict_abbreviation[str(abrv)]['count'])+ 1\n",
        "              continue\n",
        "    return self.dict_abbreviation\n",
        "\n",
        "  def dict_extraction_swartz(self, pairs):\n",
        "    for key, value in pairs.items():\n",
        "    \n",
        "      new_dict  ={}\n",
        "      abrv_ = key\n",
        "      long_f = value\n",
        "      if '(' in  long_f or ')' in long_f or abrv_ == long_f or abrv_ == long_f +'s':\n",
        "          continue\n",
        "      else:  \n",
        "          if abrv_ not in self.dict_abbreviation_swartz:\n",
        "            new_dict['long_form']= long_f\n",
        "            new_dict['count'] = int(1)\n",
        "            self.dict_abbreviation_swartz[str(abrv_)] = new_dict  \n",
        "          else:  \n",
        "            self.dict_abbreviation_swartz[str(abrv_)]['count'] = int(self.dict_abbreviation_swartz[str(abrv_)]['count'])+ 1\n",
        "            continue\n",
        "    return self.dict_abbreviation_swartz  \n",
        "  \n",
        "  def table_generation(self, dictionary_abbreviation,CSV_SAVE_PATH):\n",
        "        #CSV_SAVE_PATH = self.saving_path + 'abbreviation_table_.csv'\n",
        "        entry = {'abbreviation':[''],'long_form':[''],'count':[0]}\n",
        "        df = pd.DataFrame(entry)\n",
        "        for l in dictionary_abbreviation:\n",
        "          #print(l)\n",
        "          entry = {'abbreviation':str(l),'long_form':str(dictionary_abbreviation[l]['long_form']),'count':dictionary_abbreviation[l]['count']}\n",
        "          df = df.append(entry, ignore_index= True)\n",
        "        df = df.drop(0)\n",
        "        df = df.reset_index(drop=True)\n",
        "        df_copy = df.copy()\n",
        "        #print(df) \n",
        "\n",
        "        df['wiki_search_links'] = df.apply(lambda row: self.wikidata_lookup(row), axis =1)\n",
        "        \n",
        "\n",
        "        df.style.format({'wiki_search_links': self.make_clickable})      \n",
        "        df.to_csv(CSV_SAVE_PATH, index = None)\n",
        "  def main(self):\n",
        "      \n",
        "      if not os.path.exists(self.saving_path):\n",
        "        os.makedirs(self.saving_path) \n",
        "      \n",
        "      text = self.text_extraction()\n",
        "      \n",
        "      pairs = schwartz_hearst.extract_abbreviation_definition_pairs(doc_text= text)\n",
        "      #print('pairs',pairs)\n",
        "      \n",
        "      TEXT_ = f'Chapter_text.txt'\n",
        "      DICTIONARY_SH = f'Chapter_dictionary_SH.txt'\n",
        "      DICTIONARY_Spacy= f'Chapter_dictionary_Spacy.txt'\n",
        "      with open(self.saving_path + TEXT_, 'w') as file:\n",
        "          file.write(text)\n",
        "      \n",
        "      with open(self.saving_path + DICTIONARY_SH, 'w') as file:\n",
        "          for key, value in pairs.items():\n",
        "            #print(key, value )\n",
        "            file.write('{'+str(key)+' : '+ str(value)+\"}\")\n",
        "            file.write('\\n')\n",
        "      \n",
        "\n",
        "      nlp = spacy.load('en_core_web_sm')\n",
        "      abbreviation_pipe = AbbreviationDetector(nlp)\n",
        "      nlp.add_pipe(abbreviation_pipe)\n",
        "      doc = nlp(text)\n",
        "      #print(doc._._)\n",
        "      #print(doc._.abbreviations)\n",
        "      \n",
        "      with open(self.saving_path + DICTIONARY_Spacy, 'w') as file:\n",
        "          for abrv in doc._.abbreviations:\n",
        "            \n",
        "            #print(abrv ,abrv._.long_form)\n",
        "            #print(key, value )\n",
        "            file.write('{'+str(abrv)+' : '+ str(abrv._.long_form)+\"}\")  \n",
        "            file.write('\\n')\n",
        "      \n",
        "\n",
        "      self.scispacy_extraction(doc)\n",
        "      self.dict_extraction_swartz(pairs)\n",
        "      CSV_SAVE_PATH = self.saving_path + 'abbreviation_table_spacy.csv'\n",
        "      #dictionary_abbreviation = self.dict_abbreviation\n",
        "      dictionary_abbreviation = self.dict_abbreviation\n",
        "      self.table_generation(dictionary_abbreviation,CSV_SAVE_PATH)\n",
        "      \n",
        "      #return df"
      ],
      "metadata": {
        "id": "YPeBxkdZlFR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "html_path = '/content/semanticClimate/ipcc/ar6/wg3/Chapter06/fulltext.flow.html'\n",
        "saving_path = '/content/'\n",
        "model = ''\n",
        "\n",
        "abbreviation = abbreviation_extraction(html_path, saving_path, model)\n",
        "abbreviation.main()"
      ],
      "metadata": {
        "id": "j62uS3pTqCSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#analysis:\n",
        "df_spacy = pd.read_csv('/content/abbreviation_table_spacy.csv')\n",
        "df_swartz = pd.read_csv('/content/abbreviation_table_swartz.csv')\n",
        "print(f'Length of the df_spacy : {df_spacy.shape[0]} \\nLength of the df_swartz : {df_swartz.shape[0]}\\n')\n",
        "intersection = set(list(df_swartz.abbreviation.to_numpy())).intersection(list(df_spacy.abbreviation.to_numpy()))\n",
        "print(f'names of the abbr common in abbreviation from scpay and swartz: \\n{list(intersection)}\\n')\n",
        "print(f'Length of the intersection: {len(list(intersection))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83kT1NqDZDaY",
        "outputId": "51ff208b-5f59-491f-d5a9-bdbb1d73d8b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of the df_spacy : 60 \n",
            " Length of the df_swartz : 41\n",
            "\n",
            "names of the abbr common in abbreviation from scpay and swartz: \n",
            "['PERC', 'SMR', 'LCOE', 'LCA', 'FIT', 'ATB', 'LOHCs', 'PRIS', 'SDGs', 'TPES', 'OLEDs', 'CROI', 'IEA', 'CDR', 'LFAC', 'BECCS', 'LABs', 'LAM', 'DEV', 'VRE', 'CSP', 'LNG', 'PVSC', 'IoT', 'PtL', 'CCS', 'TFC', 'KEBA', 'HTL', 'ETS', 'CDU', 'EPCC', 'MTES', 'LPG', 'EROI']\n",
            "\n",
            "Length of the intersection: 35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "union = set(list(df_swartz.abbreviation.to_numpy())).union(list(df_spacy.abbreviation.to_numpy()))\n",
        "print(f'names of the abbr all together in abbreviation from scpay and swartz: \\n{list(intersection)}\\n')\n",
        "print(f'Length of the union: {len(list(union))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tiH4rBeleH1",
        "outputId": "82bfbe89-16e0-42c8-d5e7-0d8bf9fb0b7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "names of the abbr all together in abbreviation from scpay and swartz: \n",
            "['PERC', 'SMR', 'LCOE', 'LCA', 'FIT', 'ATB', 'LOHCs', 'PRIS', 'SDGs', 'TPES', 'OLEDs', 'CROI', 'IEA', 'CDR', 'LFAC', 'BECCS', 'LABs', 'LAM', 'DEV', 'VRE', 'CSP', 'LNG', 'PVSC', 'IoT', 'PtL', 'CCS', 'TFC', 'KEBA', 'HTL', 'ETS', 'CDU', 'EPCC', 'MTES', 'LPG', 'EROI']\n",
            "\n",
            "Length of the union: 66\n"
          ]
        }
      ]
    }
  ]
}